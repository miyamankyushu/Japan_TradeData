# æ—¥æœ¬è²¿æ˜“çµ±è¨ˆãƒ‡ãƒ¼ã‚¿è‡ªå‹•å–å¾—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆHScodeï¼‰ ğŸŒ
ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€æ—¥æœ¬ã®æ”¿åºœçµ±è¨ˆï¼ˆ[e-Stat API](https://www.e-stat.go.jp/stat-search/files?page=1&toukei=00350300&tstat=000001013143)ï¼‰ãŠã‚ˆã³ç¨é–¢ã®è¼¸å‡ºçµ±è¨ˆå“ç›®è¡¨([HP](https://www.customs.go.jp/yusyutu/index.htm))
ã‚’æ´»ç”¨ã—ã€HSã‚³ãƒ¼ãƒ‰åˆ¥ã®è²¿æ˜“çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ã§åé›†ãƒ»åŠ å·¥ãƒ»ä¿å­˜ã™ã‚‹ãŸã‚ã®Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆç¾¤ã§ã™ã€‚]



---

## ğŸ” ä¸»ãªç‰¹å¾´

- HSã‚³ãƒ¼ãƒ‰ï¼ˆå“ç›®åˆ†é¡ï¼‰ã®éšå±¤ãƒã‚¹ã‚¿è‡ªå‹•ç”Ÿæˆï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰
- e-Stat API ã‹ã‚‰ã®æœˆæ¬¡è²¿æ˜“çµ±è¨ˆãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæŒ‡å®šã•ã‚ŒãŸæœˆãƒ»å¹´ãƒ»åˆ†é¡ã§ï¼‰
- éƒ¨é¡/é¡/é …ç›®ãƒ¬ãƒ™ãƒ«ã§ã®ãƒã‚¹ã‚¿çµ±åˆ
- å›½åˆ¥ãƒ»ç¨é–¢åˆ¥ã«åˆ†é¡ã•ã‚ŒãŸå–å¼•ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§å‡ºåŠ›
- å“è³ªæ¤œæŸ»ï¼ˆæ¬ æå€¤ã€æ§‹é€ æ¬ è½ã€æ¡æ•°ãƒã‚§ãƒƒã‚¯ï¼‰ä»˜ã

---

## ğŸ“Š ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆ

```
JAPAN_TRADEDATA/
â”œâ”€â”€ library/                          # Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¾¤
â”‚   â”œâ”€â”€ get_export_data_HSitem.py     # TradeDataPipelineã‚¯ãƒ©ã‚¹
â”‚   â”œâ”€â”€ hscode_scrape.py              # HSã‚³ãƒ¼ãƒ‰å–å¾—ãƒ­ã‚¸ãƒƒã‚¯
â”œâ”€â”€ reference_master/                 # ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿é¡
â”‚   â”œâ”€â”€ area/nation.xlsx              # å›½ãƒ»åœ°åŸŸãƒã‚¹ã‚¿
â”‚   â”œâ”€â”€ counter/è²¿æ˜“çµ±è¨ˆ_å¯¾å¿œè¡¨.xlsx   # APIæƒ…å ±å¯¾å¿œè¡¨
â”‚   â”œâ”€â”€ HS_master/                    # HSã‚³ãƒ¼ãƒ‰ãƒã‚¹ã‚¿ã¨ãƒ­ã‚°
â”‚   â””â”€â”€ e-stat/month.json             # æœˆåˆ¥ã‚³ãƒ¼ãƒ‰å®šç¾©
â”œâ”€â”€ Output/                           # å‡ºåŠ›ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ MIT License
â”œâ”€â”€ requirment
â””â”€â”€ execute_HSCode_pipeline.ipynb             # ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Ÿè¡Œã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
```

---
## ğŸ›  ä½¿ç”¨æ–¹æ³•

### 1. HSã‚³ãƒ¼ãƒ‰ãƒã‚¹ã‚¿ã®ç”Ÿæˆï¼ˆ`HScode_scrape.py`ï¼‰
HSå“ç›®ãƒã‚¹ã‚¿ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»ãƒ‡ãƒ¼ã‚¿åŠ å·¥ã‚’2010å¹´ï½2025å¹´ã¾ã§è¡Œã†ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚å–å¾—çµæœã¯ã™ã§ã«`reference_master\HS_master`ã«æ ¼ç´æ¸ˆã¿ã§ã™ã€‚
```python
from library.hscode_scrape import (
    generate_customs_urls,
    fetch_and_concat_data,
    validate_and_log_hs_dataframe
)

# Specify the year, month, and item category number range
year, month = 2010, 1               # Year and month (single month)
category_range = range(1, 98)       # HS category numbers (1â€“97; 77 skipped internally)

# Run HS code scraping
urls = generate_customs_urls(year, month, category_range)
df = fetch_and_concat_data(urls)

# Run validation and generate log
log_df = validate_and_log_hs_dataframe(df, year)

# Save as CSV
df.to_csv(f'./reference_master/HS_master/HSCode_Master_{year:04d}.csv', encoding='utf-8', index=False)

```

### 2. è²¿æ˜“çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆget_export_data_HSitem.pyï¼‰
ç¨é–¢åˆ¥ãƒ»HSå“ç›®åˆ¥ãƒ»å›½åˆ¥ã«è¼¸å‡ºé‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€HSãƒã‚¹ã‚¿ã¨ç´ã¥ã‘ç­‰ã®å‡¦ç†ã‚’è¡Œã„æ•´å‚™ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’`Output`ãƒ•ã‚©ãƒ«ãƒ€ã«æ ¼ç´ã—ã¾ã™ã€‚

æ³¨æ„äº‹é …ï¼š APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™
([e-Stat API](https://www.e-stat.go.jp/api))ã®åˆ©ç”¨ç”³è«‹ã‚’è¡Œã„ã€ã”è‡ªèº«ã®`YOUR_API_KEY`ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚
```python
from library.get_export_data_HSitem import TradeDataPipeline
import pandas as pd

# Specify the type, year, and month
item_type = 'HS'  # HS (Harmonized System) item-based classification
year, month = 2024, '01'  # Year and month (single specification)
api_key = "***************"  # Replace with your own API key

# Load trade statistics master and extract target data
trade_counter_df = pd.read_excel('./reference_master/counter/trade_stat_mapping.xlsx', dtype=str)
hs_counter_df = trade_counter_df[
    (trade_counter_df['åˆ†é¡'] == item_type) & 
    (trade_counter_df['year'].astype(int) == year)
].reset_index(drop=True)

# Load country/region master
nation_df = pd.read_excel('./reference_master/area/nation.xlsx', dtype=str)

# Execute the trade data pipeline
pipeline = TradeDataPipeline(hs_counter_df, trade_counter_df, nation_df, month, api_key)
pipeline.run()
```
---
## ğŸ’¾ å‡ºåŠ›çµæœ
å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ï¼š./Output/HS_item/

å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åä¾‹ï¼š
2024_01_ç¨é–¢åˆ¥_20250423.csv

ã‚«ãƒ©ãƒ ä¾‹ï¼š
```bash
['åœ°åŸŸ', 'å›½', 'å¹´', 'æœˆ', 'ç¨é–¢', 'éƒ¨æ•°', 'éƒ¨å', 'é¡æ•°', 'é¡å', 'HSã‚³ãƒ¼ãƒ‰',
 'å¤§é …ç›®', 'ä¸­é …ç›®', 'å°é …ç›®', 'ç´°é …ç›®', 'å¾®ç´°é …ç›®', 'é …ç›®', 'é‡‘é¡', 'é‡‘é¡å˜ä½', 'æ•°é‡', 'æ•°é‡å˜ä½']
```
---
## âš ï¸ æ³¨æ„äº‹é …

- ï¼ˆå†æ²ï¼‰APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™([e-Stat API](https://www.e-stat.go.jp/api))ã®åˆ©ç”¨ç”³è«‹ã‚’è¡Œã„ã€ã”è‡ªèº«ã®`YOUR_API_KEY`ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚
- reference_master/ ä»¥ä¸‹ã«å›½åã€e-stats APIã‚³ãƒ¼ãƒ‰ã€åˆ†é¡ãªã©ã®ãƒã‚¹ã‚¿ã‚’æ ¼ç´ã—ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã‚‰ã¯ç§ãŒä½œæˆã—ã¦ã„ã‚‹ã‚‚ã®ã§ã™ã€‚é©å®œã”å¤‰æ›´ãã ã•ã„ã€‚
- ç¾çŠ¶ã»ã¨ã‚“ã©ç¢ºèªã•ã‚Œã¾ã›ã‚“ãŒã€å¹´ãƒ»æœˆãƒ»åˆ†é¡ã«ã‚ˆã£ã¦ã¯å¯¾å¿œã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆç¨é–¢ã®HTMLæ§‹é€ å¤‰åŒ–ã‚„APIä»•æ§˜ã«ã‚ˆã‚‹ï¼‰ã€‚



---
## ğŸ“ ä½œæˆè€…
Hiroki Watariï¼ˆæ¸¡åˆ© åºƒå¸Œï¼‰
ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ / ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯å€‹äººãƒ»ä¼æ¥­å•ã‚ãšè‡ªç”±ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ã§ã™ã€‚
Forkã‚„Issueæ­“è¿ã—ã¾ã™ï¼


# Japan Trade Statistics Auto-Collection Pipeline ğŸŒ
This project is a set of Python scripts for automatically collecting, processing, and saving Japanâ€™s trade statistics data by HS code. It utilizes the **e-Stat API** (provided by the Japanese government) and **web scraping of Japan Customs pages**.



---

## ğŸ” Key Features

- Automatically generates a hierarchical master of HS codes (via web scraping)
- Retrieves monthly trade statistics from the e-Stat API (by year/month/category)
- Merges and enriches data with HS classification hierarchy
- Outputs transaction data classified by country and customs office in CSV format
- Includes data validation features (missing values, structure gaps, digit checks)

---

## ğŸ“Š Project Structure

```
JAPAN_TRADEDATA/
â”œâ”€â”€ library/                          # Python modules
â”‚   â”œâ”€â”€ get_export_data_HSitem.py     # TradeDataPipeline class
â”‚   â”œâ”€â”€ hscode_scrape.py              # HS code scraping logic
â”œâ”€â”€ reference_master/                 # Master data
â”‚   â”œâ”€â”€ area/nation.xlsx              # Country/Region master
â”‚   â”œâ”€â”€ counter/trade_stat_mapping.xlsx  # API info mapping table
â”‚   â”œâ”€â”€ HS_master/                    # HS code master and logs
â”‚   â””â”€â”€ e-stat/month.json             # Monthly code definitions
â”œâ”€â”€ Output/                           # Exported CSV files
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ MIT License
â”œâ”€â”€ requirement                       # Required Python libraries
â””â”€â”€ execute_HSCode_pipeline.ipynb     # execute
```

---
## ğŸ›  How to Use

### 1. Generate the HS Code Master (`HScode_scrape.py`)
```python
from library.hscode_scrape import (
    generate_customs_urls,
    fetch_and_concat_data,
    validate_and_log_hs_dataframe
)

# Specify the year, month, and item category number range
year, month = 2010, 1               # Year and month (single month)
category_range = range(1, 98)       # HS category numbers (1â€“97; 77 skipped internally)

# Run HS code scraping
urls = generate_customs_urls(year, month, category_range)
df = fetch_and_concat_data(urls)

# Run validation and generate log
log_df = validate_and_log_hs_dataframe(df, year)

# Save as CSV
df.to_csv(f'./reference_master/HS_master/HSCode_Master_{year:04d}.csv', encoding='utf-8', index=False)

```

### 2. Retrieve Trade Statistics Data (get_export_data_HSitem.py)
```python
from library.get_export_data_HSitem import TradeDataPipeline
import pandas as pd

# Specify the type, year, and month
item_type = 'HS'  # HS (Harmonized System) item-based classification
year, month = 2024, '01'  # Year and month (single specification)
api_key = "***************"  # Replace with your own API key

# Load trade statistics master and extract target data
trade_counter_df = pd.read_excel('./reference_master/counter/trade_stat_mapping.xlsx', dtype=str)
hs_counter_df = trade_counter_df[
    (trade_counter_df['åˆ†é¡'] == item_type) & 
    (trade_counter_df['year'].astype(int) == year)
].reset_index(drop=True)

# Load country/region master
nation_df = pd.read_excel('./reference_master/area/nation.xlsx', dtype=str)

# Execute the trade data pipeline
pipeline = TradeDataPipeline(hs_counter_df, trade_counter_df, nation_df, month, api_key)
pipeline.run()
```
---
## ğŸ’¾ Output
Output folder: ./Output/HS_item/

Example output filename: 2024_01_by_customs_20250423.csv

Sample columns:
```bash
['Region', 'Country', 'Year', 'Month', 'Customs', 'Section No', 'Section Name',
 'Category No', 'Category Name', 'HS Code', 'Main Item', 'Sub Item 1', 'Sub Item 2',
 'Sub Item 3', 'Sub Item 4', 'Item', 'Amount', 'Amount Unit', 'Quantity', 'Quantity Unit']

```
---
## âš ï¸ Notes

API key is required
You must apply for and obtain an API key from the e-Stat API.

You need CSV files under reference_master/
These include classification definitions, statID mappings, and country mappings.
These are custom-created and may need to be adjusted for your use.

Some years or classifications may not be supported
This is due to changes in HTML structure of customs pages or limitations of the e-Stat API.



---
## ğŸ“ Author
Hiroki Watari
Data Scientist / Data Engineer

This project is open for customization and free to use for both personal and business purposes.
Forks, Issues, and Pull Requests are very welcome!
